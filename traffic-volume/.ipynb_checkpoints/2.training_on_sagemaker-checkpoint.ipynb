{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 2. GluonTS Training on Amazon SageMaker\n",
    "---\n",
    "\n",
    "본 모듈에서는 Amazon SageMaker API를 호출하여 모델 훈련을 수행합니다. \n",
    "\n",
    "Amazon SageMaker는 완전관리형 머신 러닝 서비스로 인프라 관리에 대해 걱정할 필요가 없으며, 딥러닝 프레임워크의 훈련/배포 컨테이너 이미지를 가져 와서\n",
    "여러분의 스크립트 코드를 쉽게 통합할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1. Training script\n",
    "---\n",
    "\n",
    "아래 코드 셀은 `src` 디렉토리에 SageMaker 훈련 스크립트인 `train.py`를 저장합니다.\n",
    "아래 스크립트가 이전 모듈의 코드와 대부분 일치하다는 점을 알 수 있습니다. 다시 말해, SageMaker 훈련 스크립트 파일은 기존 온프레미스에서 사용했던 Python 스크립트 파일과 크게 다르지 않으며, SageMaker 훈련 컨테이너에서 수행하기 위한 추가적인 환경 변수들만 설정하시면 됩니다.\n",
    "\n",
    "환경 변수 설정의 code snippet은 아래과 같습니다.\n",
    "\n",
    "```python\n",
    "# SageMaker Container environment\n",
    "parser.add_argument('--model_dir', type=str, default=os.environ['SM_MODEL_DIR'])\n",
    "parser.add_argument('--data_dir', type=str, default=os.environ['SM_CHANNEL_TRAINING'])\n",
    "parser.add_argument('--num_gpus', type=int, default=os.environ['SM_NUM_GPUS'])\n",
    "parser.add_argument('--output_dir', type=str, default=os.environ.get('SM_OUTPUT_DATA_DIR'))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./src/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./src/train.py\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import gluonts \n",
    "import numpy as np\n",
    "import argparse\n",
    "import json\n",
    "import pathlib\n",
    "from mxnet import gpu, cpu\n",
    "from mxnet.context import num_gpus\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from gluonts.dataset.util import to_pandas\n",
    "from gluonts.distribution import DistributionOutput, StudentTOutput, NegativeBinomialOutput, GaussianOutput\n",
    "from gluonts.model.simple_feedforward import SimpleFeedForwardEstimator\n",
    "from gluonts.model.deepar import DeepAREstimator\n",
    "from gluonts.trainer import Trainer\n",
    "from gluonts.evaluation import Evaluator\n",
    "from gluonts.evaluation.backtest import make_evaluation_predictions, backtest_metrics\n",
    "from gluonts.model.predictor import Predictor\n",
    "from gluonts.dataset.field_names import FieldName\n",
    "from gluonts.dataset.common import ListDataset\n",
    "\n",
    "def train(args):\n",
    "    \n",
    "    # Parse arguments\n",
    "    epochs = args.epochs\n",
    "    pred_length = args.pred_length\n",
    "    batch_size = args.batch_size\n",
    "    lr = args.lr\n",
    "    \n",
    "    model_dir = args.model_dir\n",
    "    data_dir = args.data_dir\n",
    "    num_gpus = args.num_gpus\n",
    "    output_dir = args.output_dir\n",
    "    \n",
    "    device = \"gpu\" if num_gpus > 0 else \"cpu\"\n",
    "    FREQ = 'H'\n",
    "    target_col = 'traffic_volume'\n",
    "    related_cols = ['holiday', 'temp', 'rain_1h', 'snow_1h', 'clouds_all', 'weather_main', 'weather_description']\n",
    "       \n",
    "    # Get training data\n",
    "    target_train_df = pd.read_csv(os.path.join(data_dir, 'target_train.csv'), index_col=0)\n",
    "    related_train_df = pd.read_csv(os.path.join(data_dir, 'related_train.csv'), index_col=0)\n",
    "    \n",
    "    num_steps, num_series = target_train_df.shape\n",
    "    target = target_train_df.values\n",
    "\n",
    "    pred_length = 24*7 \n",
    "    start_train_dt = '2017-01-01 00:00:00'\n",
    "    custom_ds_metadata = {'num_series': num_series,\n",
    "                          'num_steps': num_steps,\n",
    "                          'prediction_length': pred_length,\n",
    "                          'freq': FREQ,\n",
    "                          'start': start_train_dt\n",
    "                         }\n",
    "\n",
    "\n",
    "    # Prepare GlounTS Dataset\n",
    "    related_list = [related_train_df[c].values for c in related_cols]\n",
    "    train_lst = []\n",
    "\n",
    "    target_vec = target[:-pred_length].squeeze()\n",
    "    related_vecs = [related[:-pred_length].squeeze() for related in related_list]\n",
    "    dic = {FieldName.TARGET: target_vec, \n",
    "           FieldName.START: start_train_dt,\n",
    "           FieldName.FEAT_DYNAMIC_REAL: related_vecs\n",
    "          } \n",
    "    train_lst.append(dic)\n",
    "\n",
    "    test_lst = []\n",
    "\n",
    "    target_vec = target.squeeze()\n",
    "    related_vecs = [related.squeeze() for related in related_list]\n",
    "    dic = {FieldName.TARGET: target_vec, \n",
    "           FieldName.START: start_train_dt,\n",
    "           FieldName.FEAT_DYNAMIC_REAL: related_vecs\n",
    "          } \n",
    "    test_lst.append(dic)\n",
    "\n",
    "    train_ds = ListDataset(train_lst, freq=FREQ)\n",
    "    test_ds = ListDataset(test_lst, freq=FREQ)      \n",
    "\n",
    "    # Define Estimator    \n",
    "    trainer = Trainer(\n",
    "        ctx=device,\n",
    "        epochs=epochs,\n",
    "        learning_rate=lr,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    \n",
    "    mlp_estimator = SimpleFeedForwardEstimator(\n",
    "        num_hidden_dimensions=[50],\n",
    "        prediction_length=pred_length,\n",
    "        context_length=2*pred_length,\n",
    "        freq=FREQ,\n",
    "        trainer=trainer\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    mlp_predictor = mlp_estimator.train(train_ds)\n",
    "    \n",
    "    # Evaluate trained model on test data\n",
    "    forecast_it, ts_it = make_evaluation_predictions(test_ds, mlp_predictor, num_samples=100)\n",
    "    forecasts = list(forecast_it)\n",
    "    tss = list(ts_it)\n",
    "    evaluator = Evaluator(quantiles=[0.1, 0.5, 0.9])\n",
    "    agg_metrics, item_metrics = evaluator(iter(tss), iter(forecasts), num_series=len(test_ds))\n",
    "\n",
    "    metrics = ['RMSE', 'MAPE', 'wQuantileLoss[0.1]', 'wQuantileLoss[0.5]', 'wQuantileLoss[0.9]', 'mean_wQuantileLoss']\n",
    "    metrics_dic = dict((key,value) for key, value in agg_metrics.items() if key in metrics)\n",
    "    print(json.dumps(metrics_dic, indent=2))\n",
    "\n",
    "    # Save the model\n",
    "    mlp_predictor.serialize(pathlib.Path(model_dir))\n",
    "    return mlp_predictor\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    # Hyperparameter Setting\n",
    "    parser.add_argument('--epochs', type=int, default=10)\n",
    "    parser.add_argument('--pred_length', type=int, default=24*7)    \n",
    "    parser.add_argument('--batch_size', type=float, default=32)\n",
    "    parser.add_argument('--lr', type=float, default=0.001) \n",
    "    \n",
    "    # SageMaker Container Environment\n",
    "    parser.add_argument('--model_dir', type=str, default=os.environ['SM_MODEL_DIR'])\n",
    "    parser.add_argument('--data_dir', type=str, default=os.environ['SM_CHANNEL_TRAINING'])\n",
    "    parser.add_argument('--num_gpus', type=int, default=os.environ['SM_NUM_GPUS'])\n",
    "    parser.add_argument('--output_dir', type=str, default=os.environ.get('SM_OUTPUT_DATA_DIR'))\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    return args    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args = parse_args()\n",
    "    train(args)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "## 2. Training\n",
    "---\n",
    "\n",
    "스크립트가 준비되었다면 SageMaker 훈련을 수행하는 법은 매우 간단합니다. SageMaker Python SDK 활용 시, Estimator 인스턴스를 생성하고 해당 인스턴스의 `fit()` 메서드를 호출하는 것이 전부입니다. 좀 더 자세히 기술해 보면 아래와 같습니다.\n",
    "\n",
    "#### 1) Estimator 인스턴스 생성\n",
    "훈련 컨테이너에 필요한 설정들을 지정합니다. 본 핸즈온에서는 훈련 스크립트 파일이 포함된 경로인 소스 경로와(source_dir)와 훈련 스크립트 Python 파일만 엔트리포인트(entry_point)로 지정해 주면 됩니다.\n",
    "\n",
    "#### 2) `fit()` 메서드 호출\n",
    "`estimator.fit(YOUR_TRAINING_DATA_URI)` 메서드를 호출하면, 훈련에 필요한 인스턴스를 시작하고 컨테이너 환경을 시작합니다. 필수 인자값은 훈련 데이터가 존해자는 S3 경로(`s3://`)이며, 로컬 모드로 훈련 시에는 S3 경로와 로컬 경로(`file://`)를 모두 지정할 수 있습니다.\n",
    "\n",
    "인자값 중 wait은 디폴트 값으로 `wait=True`이며, 모든 훈련 작업이 완료될 때까지 코드 셀이 freezing됩니다. 만약 다른 코드 셀을 실행하거나, 다른 훈련 job을 시작하고 싶다면 `wait=False`로 설정하여 Asynchronous 모드로 변경하면 됩니다.\n",
    "\n",
    "**SageMaker 훈련이 끝나면 컨테이너 환경과 훈련 인스턴스는 자동으로 삭제됩니다.** 이 때, SageMaker는 자동으로 `SM_MODEL_DIR` 경로에 저장된 최종 모델 아티팩트를 `model.tar.gz`로 압축하여 훈련 컨테이너 환경에서 S3 bucket으로 저장합니다. 당연히, S3 bucket에 저장된 모델 아티팩트를 다운로드받아 로컬 상에서 곧바로 테스트할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.mxnet import MXNet\n",
    "\n",
    "boto_session = boto3.Session()\n",
    "sagemaker_session = sagemaker.Session(boto_session=boto_session)\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket = sagemaker.Session().default_bucket()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload data to Amazon S3\n",
    "\n",
    "Amazon SageMaker로 모델 훈련을 실행하기 위해, 데이터를 S3에 업로드합니다. 참고로, 로컬 모드에서 테스트 시에는 S3에 업로드할 필요 없이 로컬 상에서도 훈련이 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'timeseries-hol/traffic-volume/train'\n",
    "s3_bucket = boto3.Session().resource('s3').Bucket(bucket)\n",
    "\n",
    "s3_bucket.Object(os.path.join(prefix, 'target_train.csv')).upload_file('data/target_train.csv')\n",
    "s3_bucket.Object(os.path.join(prefix, 'related_train.csv')).upload_file('data/related_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Mode Training\n",
    "로컬 모드는 여러분이 작성한 훈련 및 배포 스크립트를 SageMaker에서 관리하는 클러스터에서 실행하기 전에 로컬 상(예: SageMaker 노트북 인스턴스, 개인 랩탑, 온프레미스)에서 여러분의 스크립트가 잘 동작하는지 빠르게 디버깅할 수 있는 방법입니다. 로컬 모드 훈련을 위해서는 docker-compose 또는 nvidia-docker-compose (GPU 인스턴스인 경우)가 필요하지만, SageMaker 노트북 인스턴스는 이미 docker가 설치되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = MXNet(entry_point='train.py',\n",
    "                    source_dir='src',\n",
    "                    role=role,\n",
    "                    train_instance_type='local',\n",
    "                    train_instance_count=1,\n",
    "                    framework_version='1.6.0',\n",
    "                    py_version='py3',\n",
    "                    hyperparameters = {'epochs': 2, \n",
    "                                       'lr': 0.001\n",
    "                                      }                       \n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n",
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tmpj4frcv1w_algo-1-o1cg9_1 ... \n",
      "\u001b[1BAttaching to tmpj4frcv1w_algo-1-o1cg9_12mdone\u001b[0m\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m 2020-08-27 09:39:40,810 sagemaker-training-toolkit INFO     Imported framework sagemaker_mxnet_container.training\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m 2020-08-27 09:39:40,813 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m 2020-08-27 09:39:40,826 sagemaker_mxnet_container.training INFO     MXNet training environment: {'SM_HOSTS': '[\"algo-1-o1cg9\"]', 'SM_NETWORK_INTERFACE_NAME': 'eth0', 'SM_HPS': '{\"epochs\":2,\"lr\":0.001}', 'SM_USER_ENTRY_POINT': 'train.py', 'SM_FRAMEWORK_PARAMS': '{}', 'SM_RESOURCE_CONFIG': '{\"current_host\":\"algo-1-o1cg9\",\"hosts\":[\"algo-1-o1cg9\"]}', 'SM_INPUT_DATA_CONFIG': '{\"training\":{\"TrainingInputMode\":\"File\"}}', 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data', 'SM_CHANNELS': '[\"training\"]', 'SM_CURRENT_HOST': 'algo-1-o1cg9', 'SM_MODULE_NAME': 'train', 'SM_LOG_LEVEL': '20', 'SM_FRAMEWORK_MODULE': 'sagemaker_mxnet_container.training:main', 'SM_INPUT_DIR': '/opt/ml/input', 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config', 'SM_OUTPUT_DIR': '/opt/ml/output', 'SM_NUM_CPUS': '2', 'SM_NUM_GPUS': '0', 'SM_MODEL_DIR': '/opt/ml/model', 'SM_MODULE_DIR': 's3://sagemaker-us-east-1-143656149352/mxnet-training-2020-08-27-09-39-36-364/source/sourcedir.tar.gz', 'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1-o1cg9\",\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1-o1cg9\"],\"hyperparameters\":{\"epochs\":2,\"lr\":0.001},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"mxnet-training-2020-08-27-09-39-36-364\",\"log_level\":20,\"master_hostname\":\"algo-1-o1cg9\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-143656149352/mxnet-training-2020-08-27-09-39-36-364/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-o1cg9\",\"hosts\":[\"algo-1-o1cg9\"]},\"user_entry_point\":\"train.py\"}', 'SM_USER_ARGS': '[\"--epochs\",\"2\",\"--lr\",\"0.001\"]', 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate', 'SM_CHANNEL_TRAINING': '/opt/ml/input/data/training', 'SM_HP_EPOCHS': '2', 'SM_HP_LR': '0.001'}\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m 2020-08-27 09:39:42,000 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m /usr/local/bin/python3.6 -m pip install -r requirements.txt\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m Requirement already satisfied: pandas in /usr/local/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (0.25.1)\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m Collecting gluonts==0.5.1\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m \u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/a3/828eccc0b359dde80d65909162c543b12b6277e8f8eedabccbff42d6516f/gluonts-0.5.1-py3-none-any.whl (419kB)\n",
      "\u001b[K     |████████████████████████████████| 419kB 11.4MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m \u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/site-packages (from pandas->-r requirements.txt (line 1)) (1.19.1)\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/site-packages (from pandas->-r requirements.txt (line 1)) (2020.1)\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/site-packages (from pandas->-r requirements.txt (line 1)) (2.8.0)\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.6/site-packages (from gluonts==0.5.1->-r requirements.txt (line 2)) (3.3.1)\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m Collecting pydantic~=1.1\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m \u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/5f/855412ad12817ae87f1c77d3af2fc384eaed3adfb8f3994816d75483fa20/pydantic-1.6.1-cp36-cp36m-manylinux2014_x86_64.whl (8.7MB)\n",
      "\u001b[K     |████████████████████████████████| 8.7MB 44.9MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m \u001b[?25hCollecting ujson~=1.35\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m \u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/c4/79f3409bc710559015464e5f49b9879430d8f87498ecdc335899732e5377/ujson-1.35.tar.gz (192kB)\n",
      "\u001b[K     |████████████████████████████████| 194kB 28.6MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m \u001b[?25hCollecting holidays<0.10,>=0.9\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m \u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/2c/5289263b6bb3a1ac51ddfd1f631947e2636ad9ebe8ac5e88ec37bceffc11/holidays-0.9.12.tar.gz (85kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 12.9MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m \u001b[?25hRequirement already satisfied: tqdm~=4.23 in /usr/local/lib/python3.6/site-packages (from gluonts==0.5.1->-r requirements.txt (line 2)) (4.39.0)\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/site-packages (from python-dateutil>=2.6.1->pandas->-r requirements.txt (line 1)) (1.15.0)\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m Requirement already satisfied: certifi>=2020.06.20 in /usr/local/lib/python3.6/site-packages (from matplotlib~=3.0->gluonts==0.5.1->-r requirements.txt (line 2)) (2020.6.20)\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/site-packages (from matplotlib~=3.0->gluonts==0.5.1->-r requirements.txt (line 2)) (1.2.0)\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.6/site-packages (from matplotlib~=3.0->gluonts==0.5.1->-r requirements.txt (line 2)) (7.2.0)\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/site-packages (from matplotlib~=3.0->gluonts==0.5.1->-r requirements.txt (line 2)) (0.10.0)\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/site-packages (from matplotlib~=3.0->gluonts==0.5.1->-r requirements.txt (line 2)) (2.4.7)\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m Collecting dataclasses>=0.6; python_version < \"3.7\"\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m   Downloading https://files.pythonhosted.org/packages/e1/d2/6f02df2616fd4016075f60157c7a0452b38d8f7938ae94343911e0fb0b09/dataclasses-0.7-py3-none-any.whl\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m \u001b[31mERROR: gluonts 0.5.1 has requirement pandas<1.1,>=1.0, but you'll have pandas 0.25.1 which is incompatible.\u001b[0m\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m Installing collected packages: dataclasses, pydantic, ujson, holidays, gluonts\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m     Running setup.py install for ujson ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m \u001b[?25h    Running setup.py install for holidays ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m \u001b[?25hSuccessfully installed dataclasses-0.7 gluonts-0.5.1 holidays-0.9.12 pydantic-1.6.1 ujson-1.35\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m \u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.2.2 is available.\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m 2020-08-27 09:39:47,239 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m 2020-08-27 09:39:47,256 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m 2020-08-27 09:39:47,272 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m 2020-08-27 09:39:47,286 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m \n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m Training Env:\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m \n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m {\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m         \"training\": \"/opt/ml/input/data/training\"\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m     \"current_host\": \"algo-1-o1cg9\",\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m     \"framework_module\": \"sagemaker_mxnet_container.training:main\",\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m     \"hosts\": [\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m         \"algo-1-o1cg9\"\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m     ],\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m         \"epochs\": 2,\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m         \"lr\": 0.001\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m         \"training\": {\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m         }\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m     \"job_name\": \"mxnet-training-2020-08-27-09-39-36-364\",\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m     \"master_hostname\": \"algo-1-o1cg9\",\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-143656149352/mxnet-training-2020-08-27-09-39-36-364/source/sourcedir.tar.gz\",\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m     \"module_name\": \"train\",\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m     \"num_cpus\": 2,\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m         \"current_host\": \"algo-1-o1cg9\",\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m         \"hosts\": [\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m             \"algo-1-o1cg9\"\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m         ]\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m     \"user_entry_point\": \"train.py\"\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m \n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m Environment variables:\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m \n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m SM_HOSTS=[\"algo-1-o1cg9\"]\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m SM_HPS={\"epochs\":2,\"lr\":0.001}\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m SM_USER_ENTRY_POINT=train.py\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-o1cg9\",\"hosts\":[\"algo-1-o1cg9\"]}\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m SM_INPUT_DATA_CONFIG={\"training\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m SM_CHANNELS=[\"training\"]\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m SM_CURRENT_HOST=algo-1-o1cg9\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m SM_MODULE_NAME=train\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_mxnet_container.training:main\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m SM_NUM_CPUS=2\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-143656149352/mxnet-training-2020-08-27-09-39-36-364/source/sourcedir.tar.gz\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1-o1cg9\",\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1-o1cg9\"],\"hyperparameters\":{\"epochs\":2,\"lr\":0.001},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"mxnet-training-2020-08-27-09-39-36-364\",\"log_level\":20,\"master_hostname\":\"algo-1-o1cg9\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-143656149352/mxnet-training-2020-08-27-09-39-36-364/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-o1cg9\",\"hosts\":[\"algo-1-o1cg9\"]},\"user_entry_point\":\"train.py\"}\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m SM_USER_ARGS=[\"--epochs\",\"2\",\"--lr\",\"0.001\"]\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m SM_CHANNEL_TRAINING=/opt/ml/input/data/training\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m SM_HP_EPOCHS=2\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m SM_HP_LR=0.001\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m PYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python36.zip:/usr/local/lib/python3.6:/usr/local/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/site-packages\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m \n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m \n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m /usr/local/bin/python3.6 train.py --epochs 2 --lr 0.001\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m \n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m learning rate from ``lr_scheduler`` has been overwritten by ``learning_rate`` in optimizer.\n",
      "  0% 0/50 [00:00<?, ?it/s]INFO:gluonts.trainer:Number of parameters in SimpleFeedForwardTrainingNetwork: 2830953\n",
      "100% 50/50 [00:02<00:00, 19.07it/s, epoch=1/2, avg_epoch_loss=9.74]\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m INFO:gluonts.trainer:Epoch[0] Elapsed time 2.624 seconds\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m INFO:gluonts.trainer:Epoch[0] Evaluation metric 'epoch_loss'=9.741515\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m INFO:gluonts.trainer:Epoch[1] Learning rate is 0.001\n",
      "100% 50/50 [00:02<00:00, 23.98it/s, epoch=2/2, avg_epoch_loss=8.96]\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m INFO:gluonts.trainer:Epoch[1] Elapsed time 2.087 seconds\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m INFO:gluonts.trainer:Epoch[1] Evaluation metric 'epoch_loss'=8.964527\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m INFO:gluonts.trainer:Loading parameters from best epoch (1)\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m INFO:gluonts.trainer:Final loss: 8.964526653289795 (occurred at epoch 1)\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m INFO:gluonts.trainer:End model training\n",
      "Running evaluation: 100% 1/1 [00:00<00:00, 55.33it/s]\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m {\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m   \"MAPE\": 0.5354340653792763,\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m   \"RMSE\": 1978.1182014853457,\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m   \"wQuantileLoss[0.1]\": 0.15264281875717967,\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m   \"wQuantileLoss[0.5]\": 0.33357038159180474,\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m   \"wQuantileLoss[0.9]\": 0.23042030205485695,\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m   \"mean_wQuantileLoss\": 0.2388778341346138\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m WARNING:root:Serializing RepresentableBlockPredictor instances does not save the prediction network structure in a backwards-compatible manner. Be careful not to use this method in production.\n",
      "\u001b[36malgo-1-o1cg9_1  |\u001b[0m 2020-08-27 09:39:55,483 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "\u001b[36mtmpj4frcv1w_algo-1-o1cg9_1 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "s3_input = sagemaker.s3_input(s3_data='s3://{}/{}'.format(bucket, prefix))\n",
    "estimator.fit(s3_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID        IMAGE                                                                        COMMAND                  CREATED             STATUS              PORTS                              NAMES\r\n",
      "928b8e22896b        763104351884.dkr.ecr.us-east-1.amazonaws.com/mxnet-inference:1.6.0-cpu-py3   \"python /usr/local/b…\"   21 hours ago        Up 21 hours         0.0.0.0:8080->8080/tcp, 8081/tcp   tmp37beh3kk_algo-1-kk1nm_1\r\n"
     ]
    }
   ],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = MXNet(entry_point='train.py',\n",
    "                    source_dir='src',\n",
    "                    role=role,\n",
    "                    train_instance_type='ml.c5.xlarge',\n",
    "                    train_instance_count=1,\n",
    "                    framework_version='1.4.1',\n",
    "                    py_version='py3',\n",
    "                    hyperparameters = {'epochs': 2, \n",
    "                                       'lr': 0.001,\n",
    "                                      }                       \n",
    "                   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3_input = sagemaker.TrainingInput(s3_data='s3://{}/{}'.format(bucket, prefix), content_type='csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n",
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-26 07:58:44 Starting - Starting the training job...\n",
      "2020-08-26 07:58:46 Starting - Launching requested ML instances......\n",
      "2020-08-26 08:00:01 Starting - Preparing the instances for training...\n",
      "2020-08-26 08:00:30 Downloading - Downloading input data...\n",
      "2020-08-26 08:01:01 Training - Training image download completed. Training in progress.\u001b[34m2020-08-26 08:01:02,233 sagemaker-containers INFO     Imported framework sagemaker_mxnet_container.training\u001b[0m\n",
      "\u001b[34m2020-08-26 08:01:02,236 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-08-26 08:01:02,249 sagemaker_mxnet_container.training INFO     MXNet training environment: {'SM_HOSTS': '[\"algo-1\"]', 'SM_NETWORK_INTERFACE_NAME': 'eth0', 'SM_HPS': '{\"epochs\":2,\"lr\":0.001}', 'SM_USER_ENTRY_POINT': 'train.py', 'SM_FRAMEWORK_PARAMS': '{}', 'SM_RESOURCE_CONFIG': '{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}', 'SM_INPUT_DATA_CONFIG': '{\"training\":{\"ContentType\":\"csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}', 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data', 'SM_CHANNELS': '[\"training\"]', 'SM_CURRENT_HOST': 'algo-1', 'SM_MODULE_NAME': 'train', 'SM_LOG_LEVEL': '20', 'SM_FRAMEWORK_MODULE': 'sagemaker_mxnet_container.training:main', 'SM_INPUT_DIR': '/opt/ml/input', 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config', 'SM_OUTPUT_DIR': '/opt/ml/output', 'SM_NUM_CPUS': '4', 'SM_NUM_GPUS': '0', 'SM_MODEL_DIR': '/opt/ml/model', 'SM_MODULE_DIR': 's3://sagemaker-us-east-1-143656149352/mxnet-training-2020-08-26-07-58-43-498/source/sourcedir.tar.gz', 'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":2,\"lr\":0.001},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"ContentType\":\"csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"mxnet-training-2020-08-26-07-58-43-498\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-143656149352/mxnet-training-2020-08-26-07-58-43-498/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}', 'SM_USER_ARGS': '[\"--epochs\",\"2\",\"--lr\",\"0.001\"]', 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate', 'SM_CHANNEL_TRAINING': '/opt/ml/input/data/training', 'SM_HP_LR': '0.001', 'SM_HP_EPOCHS': '2'}\u001b[0m\n",
      "\u001b[34m2020-08-26 08:01:05,542 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-08-26 08:01:05,542 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-08-26 08:01:05,543 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-08-26 08:01:05,543 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.6 -m pip install -U . -r requirements.txt\u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mCollecting gluonts==0.5.1 (from -r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/e5/a3/828eccc0b359dde80d65909162c543b12b6277e8f8eedabccbff42d6516f/gluonts-0.5.1-py3-none-any.whl (419kB)\u001b[0m\n",
      "\u001b[34mCollecting pydantic~=1.1 (from gluonts==0.5.1->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/25/69/4be0f2caa2ae3424cd34c0f934b460a02f01aa6897b1d58fc056664b15b7/pydantic-1.6.1-py36.py37.py38-none-any.whl (99kB)\u001b[0m\n",
      "\u001b[34mCollecting pandas<1.1,>=1.0 (from gluonts==0.5.1->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/c0/95/cb9820560a2713384ef49060b0087dfa2591c6db6f240215c2bce1f4211c/pandas-1.0.5-cp36-cp36m-manylinux1_x86_64.whl (10.1MB)\u001b[0m\n",
      "\n",
      "2020-08-26 08:01:35 Uploading - Uploading generated training model\n",
      "2020-08-26 08:01:35 Completed - Training job completed\n",
      "\u001b[34mCollecting numpy~=1.16 (from gluonts==0.5.1->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/b1/9a/7d474ba0860a41f771c9523d8c4ea56b084840b5ca4092d96bdee8a3b684/numpy-1.19.1-cp36-cp36m-manylinux2010_x86_64.whl (14.5MB)\u001b[0m\n",
      "\u001b[34mCollecting tqdm~=4.23 (from gluonts==0.5.1->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/28/7e/281edb5bc3274dfb894d90f4dbacfceaca381c2435ec6187a2c6f329aed7/tqdm-4.48.2-py2.py3-none-any.whl (68kB)\u001b[0m\n",
      "\u001b[34mCollecting matplotlib~=3.0 (from gluonts==0.5.1->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/96/a7/b6fa244fd8a8814ef9408c8a5a7e4ed0340e232a6f0ce2046b42e50672c0/matplotlib-3.3.1-cp36-cp36m-manylinux1_x86_64.whl (11.6MB)\u001b[0m\n",
      "\u001b[34mCollecting ujson~=1.35 (from gluonts==0.5.1->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/16/c4/79f3409bc710559015464e5f49b9879430d8f87498ecdc335899732e5377/ujson-1.35.tar.gz (192kB)\u001b[0m\n",
      "\u001b[34mCollecting holidays<0.10,>=0.9 (from gluonts==0.5.1->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/51/2c/5289263b6bb3a1ac51ddfd1f631947e2636ad9ebe8ac5e88ec37bceffc11/holidays-0.9.12.tar.gz (85kB)\u001b[0m\n",
      "\u001b[34mCollecting dataclasses>=0.6; python_version < \"3.7\" (from pydantic~=1.1->gluonts==0.5.1->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/e1/d2/6f02df2616fd4016075f60157c7a0452b38d8f7938ae94343911e0fb0b09/dataclasses-0.7-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/site-packages (from pandas<1.1,>=1.0->gluonts==0.5.1->-r requirements.txt (line 1)) (2019.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/site-packages (from pandas<1.1,>=1.0->gluonts==0.5.1->-r requirements.txt (line 1)) (2.8.0)\u001b[0m\n",
      "\u001b[34mCollecting kiwisolver>=1.0.1 (from matplotlib~=3.0->gluonts==0.5.1->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/ae/23/147de658aabbf968324551ea22c0c13a00284c4ef49a77002e91f79657b7/kiwisolver-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (88kB)\u001b[0m\n",
      "\u001b[34mCollecting cycler>=0.10 (from matplotlib~=3.0->gluonts==0.5.1->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/f7/d2/e07d3ebb2bd7af696440ce7e754c59dd546ffe1bbe732c8ab68b9c834e61/cycler-0.10.0-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[34mCollecting certifi>=2020.06.20 (from matplotlib~=3.0->gluonts==0.5.1->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/5e/c4/6c4fe722df5343c33226f0b4e0bb042e4dc13483228b4718baf286f86d87/certifi-2020.6.20-py2.py3-none-any.whl (156kB)\u001b[0m\n",
      "\u001b[34mCollecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 (from matplotlib~=3.0->gluonts==0.5.1->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/bb/488841f56197b13700afd5658fc279a2025a39e22449b7cf29864669b15d/pyparsing-2.4.7-py2.py3-none-any.whl (67kB)\u001b[0m\n",
      "\u001b[34mCollecting pillow>=6.2.0 (from matplotlib~=3.0->gluonts==0.5.1->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/30/bf/92385b4262178ca22b34f82e0e09c2922eb351fe39f3cc7b8ba9ea555b41/Pillow-7.2.0-cp36-cp36m-manylinux1_x86_64.whl (2.2MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/site-packages (from holidays<0.10,>=0.9->gluonts==0.5.1->-r requirements.txt (line 1)) (1.12.0)\u001b[0m\n",
      "\u001b[34mERROR: mxnet-mkl 1.4.1 has requirement numpy<1.15.0,>=1.8.2, but you'll have numpy 1.19.1 which is incompatible.\u001b[0m\n",
      "\u001b[34mInstalling collected packages: dataclasses, pydantic, numpy, pandas, tqdm, kiwisolver, cycler, certifi, pyparsing, pillow, matplotlib, ujson, holidays, gluonts, train\n",
      "  Found existing installation: numpy 1.14.5\n",
      "    Uninstalling numpy-1.14.5:\n",
      "      Successfully uninstalled numpy-1.14.5\u001b[0m\n",
      "\u001b[34m  Found existing installation: pandas 0.24.1\n",
      "    Uninstalling pandas-0.24.1:\n",
      "      Successfully uninstalled pandas-0.24.1\u001b[0m\n",
      "\u001b[34m  Found existing installation: certifi 2019.6.16\n",
      "    Uninstalling certifi-2019.6.16:\n",
      "      Successfully uninstalled certifi-2019.6.16\n",
      "  Found existing installation: Pillow 5.4.1\n",
      "    Uninstalling Pillow-5.4.1:\n",
      "      Successfully uninstalled Pillow-5.4.1\u001b[0m\n",
      "\u001b[34m  Running setup.py install for ujson: started\u001b[0m\n",
      "\u001b[34m    Running setup.py install for ujson: finished with status 'done'\n",
      "  Running setup.py install for holidays: started\n",
      "    Running setup.py install for holidays: finished with status 'done'\n",
      "  Running setup.py install for train: started\n",
      "    Running setup.py install for train: finished with status 'done'\u001b[0m\n",
      "\u001b[34mSuccessfully installed certifi-2020.6.20 cycler-0.10.0 dataclasses-0.7 gluonts-0.5.1 holidays-0.9.12 kiwisolver-1.2.0 matplotlib-3.3.1 numpy-1.19.1 pandas-1.0.5 pillow-7.2.0 pydantic-1.6.1 pyparsing-2.4.7 tqdm-4.48.2 train-1.0.0 ujson-1.35\u001b[0m\n",
      "\u001b[34mWARNING: You are using pip version 19.1.1, however version 20.2.2 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-08-26 08:01:16,908 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-08-26 08:01:16,920 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_mxnet_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"lr\": 0.001,\n",
      "        \"epochs\": 2\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"ContentType\": \"csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"mxnet-training-2020-08-26-07-58-43-498\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-143656149352/mxnet-training-2020-08-26-07-58-43-498/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":2,\"lr\":0.001}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"ContentType\":\"csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_mxnet_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-143656149352/mxnet-training-2020-08-26-07-58-43-498/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":2,\"lr\":0.001},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"ContentType\":\"csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"mxnet-training-2020-08-26-07-58-43-498\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-143656149352/mxnet-training-2020-08-26-07-58-43-498/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"2\",\"--lr\",\"0.001\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_LR=0.001\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=2\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/usr/local/bin:/usr/local/lib/python36.zip:/usr/local/lib/python3.6:/usr/local/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.6 -m train --epochs 2 --lr 0.001\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/50 [00:00<?, ?it/s]#015100%|██████████| 50/50 [00:03<00:00, 15.56it/s, epoch=1/2, avg_epoch_loss=3.83]\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/50 [00:00<?, ?it/s]#015100%|██████████| 50/50 [00:02<00:00, 16.97it/s, epoch=2/2, avg_epoch_loss=2.91]\u001b[0m\n",
      "\u001b[34m#015Running evaluation:   0%|          | 0/50 [00:00<?, ?it/s]#015Running evaluation: 100%|██████████| 50/50 [00:00<00:00, 1613.07it/s]\u001b[0m\n",
      "\u001b[34m{\n",
      "  \"MAPE\": 0.07068708479134657,\n",
      "  \"RMSE\": 3.869580660857143,\n",
      "  \"wQuantileLoss[0.1]\": 0.02759092363478594,\n",
      "  \"wQuantileLoss[0.5]\": 0.06758248968959513,\n",
      "  \"wQuantileLoss[0.9]\": 0.03177319624221301,\n",
      "  \"mean_wQuantileLoss\": 0.04231553652219802\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mWARNING:root:Serializing RepresentableBlockPredictor instances does not save the prediction network structure in a backwards-compatible manner. Be careful not to use this method in production.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2020-08-26 08:01:27,047 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "Training seconds: 65\n",
      "Billable seconds: 65\n"
     ]
    }
   ],
   "source": [
    "s3_input = sagemaker.s3_input(s3_data='s3://{}/{}'.format(bucket, prefix), content_type='csv')\n",
    "estimator.fit(s3_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('src')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = pathlib.Path('./src/')   \n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model_dir = './model'\n",
    "!rm -rf $local_model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-143656149352/mxnet-training-2020-08-26-07-58-43-498/output/\n",
      "2020-08-26 08:01:31      59970 model.tar.gz\n",
      "download: s3://sagemaker-us-east-1-143656149352/mxnet-training-2020-08-26-07-58-43-498/output/model.tar.gz to model/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "import json , os\n",
    "\n",
    "s3_model_dir = estimator.model_data.replace('model.tar.gz', '')\n",
    "print(s3_model_dir)\n",
    "!aws s3 ls {s3_model_dir}\n",
    "\n",
    "if not os.path.exists(local_model_dir):\n",
    "    os.makedirs(local_model_dir)\n",
    "\n",
    "!aws s3 cp {s3_model_dir}model.tar.gz {local_model_dir}/model.tar.gz\n",
    "!tar -xzf {local_model_dir}/model.tar.gz -C {local_model_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_transform.json  prediction_net-0000.params   version.json\r\n",
      "model.tar.gz\t      prediction_net-network.json\r\n",
      "parameters.json       type.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mxnet\n",
    "mxnet.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
