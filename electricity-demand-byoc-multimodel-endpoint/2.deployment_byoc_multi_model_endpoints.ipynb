{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 2.  BYOC(Bring Your Own Container): Multi-Model Endpoint Deployment on MMS(Multi Model Server)\n",
    "---\n",
    "\n",
    "본 모듈에서는 멀티모델 엔드포인트로 여러 모델들을 단일 호스팅 인스턴스에 배포합니다. 이를 위해  MMS(Multi Model Server)와 SageMaker Inference Toolkit가 포된 사용자 정의 컨테이너를 빌드합니다. 노트북 실행에는 약 30분 가량 소요됩니다. 사용자 정의 컨테이너를 빌드하여 모델을 배포하는 모범 예시는 아래 웹페이지를 참좨 주세요.\n",
    "- https://github.com/awslabs/amazon-sagemaker-examples/tree/master/advanced_functionality/multi_model_bring_your_own\n",
    "\n",
    "### MMS \n",
    "2017년 12월 초  MXNet 1.0 릴리스 시 최초 공개된 모델 서빙 오픈소스 프레임워크로, 단일 컨테이너 내에서 여러 모델들을 호스팅하고, 모델을 컨터이너에 동적으로 로드 및 언로드하고 멀티모델 엔드포인트에 필요한 http 프론트엔드 및 모델 관리 기능을 제공합니다. 자세한 내용은 아래 웹페이지를 참조해 주세요.\n",
    "- https://github.com/awslabs/multi-model-server\n",
    "\n",
    "### SageMaker Inference Toolkit\n",
    "SageMaker 상에서 MMS를 좀 더 쉽고 편하게 배포할 수 있는 high-level 어플리케이션으로 배포한 툴킷으로 멀티모델 엔드포인트를 쉽게 배포할 수 있는 설정 및 인터페이스를 지원합니다. 자세한 내용은 아래 웹페이지를 참조해 주세요.\n",
    "- https://github.com/aws/sagemaker-inference-toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1. Build Your Own Container\n",
    "---\n",
    "사용자 지정 SageMaker 컨테이너를 로컬에서 빌드하고 Amazon ECR(Elastic Container Registry)에 등록합니다. ECR은 컨테이너 이미지를 손쉽게 저장, 관리 및 배포할 수 있는 완전 관리형 도커 컨테이너 레포지토리입니다.\n",
    "\n",
    "### 1.1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jsonlines in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (2.0.0)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "!pip install jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import jsonlines\n",
    "import json\n",
    "import time\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "from time import gmtime, strftime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Define model handler\n",
    "\n",
    "`container/model_handler.py` 파일은 GluonTS로 훈련한 모델을 추론하는 사용자 정의 핸들러 클래스입니다.\n",
    "\n",
    "모델이 메모리에 로드될 때 `initialize` 메소드가 호출됩니다. 이 예제에서는 model_dir의 모델 아티팩트를 GluonTS Predictor 클래스로 로드합니다.\n",
    "\n",
    "모델을 호출할 때 `handle` 메소드가 호출됩니다. 이 예시에서는 입력 페이로드의 유효성을 검사한 다음 입력값을 GluonTS Predictor 클래스로 전달하여 출력을 반환합니다. 이 핸들러 클래스는 컨테이너에 로드된 모든 모델에 대해 인스턴스화되므로, 핸들러의 상태는 모델간에 공유되지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting container/model_handler.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile container/model_handler.py\n",
    "\"\"\"\n",
    "ModelHandler defines an example model handler for load and inference requests for MXNet CPU models\n",
    "\"\"\"\n",
    "from collections import namedtuple\n",
    "import glob\n",
    "import json\n",
    "import logging\n",
    "import io\n",
    "import os\n",
    "import re\n",
    "\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "from gluonts.model.predictor import Predictor\n",
    "from gluonts.dataset.common import ListDataset\n",
    "\n",
    "class ModelHandler(object):\n",
    "    \"\"\"\n",
    "    A sample Model handler implementation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.initialized = False\n",
    "        self.mx_model = None\n",
    "        self.shapes = None\n",
    "    \n",
    "    def load_model(self, model_path):\n",
    "        try:\n",
    "            predictor = Predictor.deserialize(Path(model_path))\n",
    "            print('Model loaded from %s'%model_path)\n",
    "        except:\n",
    "            print('Unable to load the model %s'%model_path)\n",
    "            sys.exit(1)\n",
    "        return predictor\n",
    "\n",
    "    def initialize(self, context):\n",
    "        \"\"\"\n",
    "        Initialize model. This will be called during model loading time\n",
    "        :param context: Initial context contains model server system properties.\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.initialized = True\n",
    "        properties = context.system_properties\n",
    "        # Contains the url parameter passed to the load request\n",
    "        model_dir = properties.get(\"model_dir\") \n",
    "        gpu_id = properties.get(\"gpu_id\")\n",
    "\n",
    "        # Load Gluonts Model\n",
    "        self.mx_model = self.load_model(model_dir)\n",
    "\n",
    "    def preprocess(self, request):\n",
    "        \"\"\"\n",
    "        Transform raw input into model input data.\n",
    "        :param request: list of raw requests\n",
    "        :return: list of preprocessed model input data\n",
    "        \"\"\"\n",
    "        # Take the input data and pre-process it make it inference ready\n",
    "\n",
    "        json_list = []\n",
    "        # for each request\n",
    "        for idx, data in enumerate(request):\n",
    "            # Read the bytearray of the jsonline from the input\n",
    "            jsonline_arr = data.get('body')  \n",
    "            # Input json is in bytearray, convert it to string\n",
    "            jsonline_str = jsonline_arr.decode(\"utf-8\")\n",
    "            # split the json lines\n",
    "            json_list_request = []\n",
    "            # for each time series\n",
    "            for line in io.StringIO(jsonline_str):\n",
    "                json_record = json.loads(line)\n",
    "                json_list_request.append(json_record)\n",
    "            json_list.append(json_list_request)\n",
    "        return json_list\n",
    "\n",
    "    def inference(self, model_input):\n",
    "        \"\"\"\n",
    "        Internal inference methods\n",
    "        :param model_input: transformed model input data list\n",
    "        :return: list of inference output in NDArray\n",
    "        \"\"\"\n",
    "        forecast_list = []\n",
    "        for model_input_request in model_input:\n",
    "            forecast = list(self.mx_model.predict(ListDataset(\n",
    "                      model_input_request,\n",
    "                      freq = self.mx_model.freq\n",
    "            )))\n",
    "            forecast_list.append(forecast)\n",
    "        return forecast_list\n",
    "\n",
    "    def postprocess(self, inference_output):\n",
    "        \"\"\"\n",
    "        Return predict result in as list.\n",
    "        :param inference_output: list of inference output\n",
    "        :return: list of predict results\n",
    "        \"\"\"\n",
    "        ret = []\n",
    "        quantiles = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "        # for each request\n",
    "        for inference_output_request in inference_output:\n",
    "            ret_request = []\n",
    "            # for each time series\n",
    "            for i in inference_output_request:\n",
    "                l = {}\n",
    "                l[\"item_id\"] = i.item_id\n",
    "                l[\"quantiles\"] = {}\n",
    "                for q in quantiles:\n",
    "                    l[\"quantiles\"][str(q)] = i.quantile(q).tolist()\n",
    "                l[\"mean\"] = i.mean.tolist()\n",
    "                ret_request.append(json.dumps(l))\n",
    "            ret.append('\\n'.join(ret_request) + '\\n')\n",
    "        return ret\n",
    "        \n",
    "    def handle(self, data, context):\n",
    "        \"\"\"\n",
    "        Call preprocess, inference and post-process functions\n",
    "        :param data: input data\n",
    "        :param context: mms context\n",
    "        \"\"\"\n",
    "        \n",
    "        model_input = self.preprocess(data)\n",
    "        model_out = self.inference(model_input)\n",
    "        return self.postprocess(model_out)\n",
    "\n",
    "_service = ModelHandler()\n",
    "\n",
    "\n",
    "def handle(data, context):\n",
    "    if not _service.initialized:\n",
    "        _service.initialize(context)\n",
    "\n",
    "    if data is None:\n",
    "        return None\n",
    "\n",
    "    return _service.handle(data, context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Unit testing for the model handler\n",
    "\n",
    "사용자 정의 도커 컨테이너를 빌드하기 전에 아래와 같이 유닛 테스트(__`container/test_model_handler.py`__) 를 수행하는 것을 권장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= test session starts ==============================\n",
      "platform linux -- Python 3.6.13, pytest-6.2.2, py-1.10.0, pluggy-0.13.1 -- /home/ec2-user/anaconda3/envs/mxnet_p36/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/ec2-user/SageMaker/time-series-on-aws-hol/electricity-demand-byoc-multimodel-endpoint/container\n",
      "plugins: anyio-2.1.0\n",
      "collecting ... collected 5 items\n",
      "\n",
      "test_model_handler.py::test_load_model PASSED                            [ 20%]\n",
      "test_model_handler.py::test_initialize PASSED                            [ 40%]\n",
      "test_model_handler.py::test_preprocess PASSED                            [ 60%]\n",
      "test_model_handler.py::test_handle[5-quantiles0] PASSED                  [ 80%]\n",
      "test_model_handler.py::test_handle[25-quantiles1] PASSED                 [100%]\n",
      "\n",
      "============================== 5 passed in 5.46s ===============================\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "cd container\n",
    "pytest -v test_model_handler.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Define Docker Entrypoint\n",
    "\n",
    "MMS(Multi Model Server)는 프레임워크에 구애받지 않도록 설계되었기 때문에, 모든 프레임워크의 백엔드 엔진 역할을 할 수 있는 충분한 유연성을 제공합니다.\n",
    "\n",
    "SageMaker Inference Toolkit은 SageMaker 멀티 모델 엔드포인트와 호환되는 방식으로 MMS를 부트스트랩하는 라이브러리이며 모델 당 worker 수(number of workers per model)와 같은 중요한 파라메터를 조정할 수 있습니다. \n",
    "\n",
    "이 예제의 추론 컨테이너는 Inference Toolkit을 사용하여 __`container/dockerd-entrypoint.py`__ 파일의 main()함수에서 MMS를 시작합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting container/dockerd-entrypoint.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile container/dockerd-entrypoint.py\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "import shlex\n",
    "import os\n",
    "from retrying import retry\n",
    "from subprocess import CalledProcessError\n",
    "from sagemaker_inference import model_server\n",
    "\n",
    "def _retry_if_error(exception):\n",
    "    return isinstance(exception, CalledProcessError or OSError)\n",
    "\n",
    "@retry(stop_max_delay=1000 * 50,\n",
    "       retry_on_exception=_retry_if_error)\n",
    "def _start_mms():\n",
    "    # by default the number of workers per model is 1, but we can configure it through the\n",
    "    # environment variable below if desired.\n",
    "    # os.environ['SAGEMAKER_MODEL_SERVER_WORKERS'] = '2'\n",
    "    model_server.start_model_server(handler_service='/home/model-server/model_handler.py:handle')\n",
    "\n",
    "def main():\n",
    "    if sys.argv[1] == 'serve':\n",
    "        _start_mms()\n",
    "    else:\n",
    "        subprocess.check_call(shlex.split(' '.join(sys.argv[1:])))\n",
    "\n",
    "    # prevent docker exit\n",
    "    subprocess.call(['tail', '-f', '/dev/null'])\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Building and registering a container\n",
    "\n",
    "아래의 셸 스크립트는 먼저 MMS를 프런트엔드로 사용하는 사용자 정의 도커 이미지를 빌드합니다. 그런 다음 사용자 계정의 ECR 리포지토리에 도커 이미지를 업로드합니다. 최초로 도커 이미지 빌드 시에는 수행 시간이 오래 소요됩니다.\n",
    "\n",
    "#### Tip\n",
    "아래 코드 셀에서 No space left 관련 오류가 발생하면, 도커 이미지/컨테이너가 저장될 폴더를 SageMaker 볼륨으로 변경해 주세요.\n",
    "\n",
    "`$ mkdir -p /home/ec2-user/SageMaker/docker_dir`\n",
    "`$ sudo vim /etc/sysconfig/docker`\n",
    "\n",
    "`/etc/sysconfig/docker` 파일을 아래 내용으로 수정합니다.\n",
    "\n",
    "`OPTIONS=\"--default-ulimit nofile=1024:4096 -g /home/ec2-user/SageMaker/docker_dir\"`\n",
    "\n",
    "아래 커맨드로 도커를 재시작 후, 폴더가 정상적으로 변경되었는지 확인합니다.\n",
    "\n",
    "`$ sudo service docker restart`\n",
    "`% sudo docker info | grep Root`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "sha256:8a5bd537b2381b4cc138292f8c5f8b36b5af568bd8ac38ca6096feaf7306d765\n",
      "The push refers to repository [143656149352.dkr.ecr.us-east-1.amazonaws.com/demo-sagemaker-multimodel-gluonts]\n",
      "de603ec13ff6: Preparing\n",
      "d1a8893f3396: Preparing\n",
      "37fa9d8880f0: Preparing\n",
      "6fc2d732ad49: Preparing\n",
      "d52da9f1bb83: Preparing\n",
      "139386551f5a: Preparing\n",
      "40edb07decfe: Preparing\n",
      "4581ecc3dbe5: Preparing\n",
      "97eb5c7d2a69: Preparing\n",
      "fe8c9427beab: Preparing\n",
      "c56acba6bc0f: Preparing\n",
      "6f1a2ed3991b: Preparing\n",
      "6f15325cc380: Preparing\n",
      "1e77dd81f9fa: Preparing\n",
      "030309cad0ba: Preparing\n",
      "6f1a2ed3991b: Waiting\n",
      "97eb5c7d2a69: Waiting\n",
      "6f15325cc380: Waiting\n",
      "fe8c9427beab: Waiting\n",
      "c56acba6bc0f: Waiting\n",
      "1e77dd81f9fa: Waiting\n",
      "030309cad0ba: Waiting\n",
      "4581ecc3dbe5: Waiting\n",
      "40edb07decfe: Waiting\n",
      "139386551f5a: Waiting\n",
      "de603ec13ff6: Pushed\n",
      "d1a8893f3396: Pushed\n",
      "37fa9d8880f0: Pushed\n",
      "d52da9f1bb83: Pushed\n",
      "97eb5c7d2a69: Layer already exists\n",
      "fe8c9427beab: Layer already exists\n",
      "c56acba6bc0f: Layer already exists\n",
      "6f1a2ed3991b: Layer already exists\n",
      "6fc2d732ad49: Pushed\n",
      "6f15325cc380: Layer already exists\n",
      "1e77dd81f9fa: Layer already exists\n",
      "030309cad0ba: Layer already exists\n",
      "4581ecc3dbe5: Pushed\n",
      "40edb07decfe: Pushed\n",
      "139386551f5a: Pushed\n",
      "latest: digest: sha256:ef4efc7fd4af26dd7efa5c72c52b181a4f1b69b1533d1cb40f302e6a0713ddd0 size: 3443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name=demo-sagemaker-multimodel-gluonts\n",
    "\n",
    "cd container\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "$(aws ecr get-login --region ${region} --no-include-email)\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build -q -t ${algorithm_name} .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 2. Deploy Models as Sagemaker Multi-Model Endpoint and Invoke the Endpoint\n",
    "---\n",
    "\n",
    "컨테이너를 ECR에 등록한 후, 모델을 SageMaker 멀티모델 엔드포인트로 배포하고 엔드포인트를 호출합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Set up the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저, 멀티모델 엔드포인트에서 호출할 모델 아티팩트의 S3 버킷과 prefix를 정의해야 합니다. 또한, 모델 아티팩트 및 ECR 이미지에 대한 액세스 권한을 부여할 IAM role을 정의해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client = boto3.client(service_name='sagemaker')\n",
    "runtime_sm_client = boto3.client(service_name='sagemaker-runtime')\n",
    "\n",
    "account_id = boto3.client('sts').get_caller_identity()['Account']\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "bucket = 'sagemaker-{}-{}'.format(region, account_id)\n",
    "prefix = 'demo-multimodel-gluonts-endpoint'\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "models_dir = \"models\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Create a multi-model endpoint\n",
    "#### Import models into hosting\n",
    "\n",
    "다중 모델 엔드 포인트에 대한 모델 엔터티를 생성할 때 컨테이너의 `ModelDataUrl`은 엔드포인트에서 호출할 수 있는 모델 아티팩트가 있는 S3 prefix입니다. 나머지 S3 경로는 모델을 호출할 때 지정됩니다.\n",
    "\n",
    "또한, 컨테이너가 여러 모델들을 호스팅 함을 나타내기 위해 `'Mode': 'MultiModel'`로 지정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: DEMO-MultiModelGluonTSModel2021-04-08-14-47-12\n",
      "Model data Url: https://s3-us-east-1.amazonaws.com/sagemaker-us-east-1-143656149352/demo-multimodel-gluonts-endpoint/models/\n",
      "Container image: 143656149352.dkr.ecr.us-east-1.amazonaws.com/demo-sagemaker-multimodel-gluonts:latest\n",
      "Model Arn: arn:aws:sagemaker:us-east-1:143656149352:model/demo-multimodelgluontsmodel2021-04-08-14-47-12\n"
     ]
    }
   ],
   "source": [
    "model_name = 'DEMO-MultiModelGluonTSModel' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "model_url = 'https://s3-{}.amazonaws.com/{}/{}/{}/'.format(region, bucket, prefix, models_dir)\n",
    "container = '{}.dkr.ecr.{}.amazonaws.com/{}:latest'.format(account_id, region, 'demo-sagemaker-multimodel-gluonts')\n",
    "\n",
    "print('Model name: ' + model_name)\n",
    "print('Model data Url: ' + model_url)\n",
    "print('Container image: ' + container)\n",
    "\n",
    "container = {\n",
    "    'Image': container,\n",
    "    'ModelDataUrl': model_url,\n",
    "    'Mode': 'MultiModel'\n",
    "}\n",
    "\n",
    "create_model_response = sm_client.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = role,\n",
    "    Containers = [container])\n",
    "\n",
    "print(\"Model Arn: \" + create_model_response['ModelArn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create endpoint configuration\n",
    "\n",
    "엔드포인트 설정 생성은 단일 모델 엔드포인트와 동일한 방식입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint config name: DEMO-MultiModelGluonTSEndpointConfig-2021-04-08-14-47-12\n",
      "Endpoint config Arn: arn:aws:sagemaker:us-east-1:143656149352:endpoint-config/demo-multimodelgluontsendpointconfig-2021-04-08-14-47-12\n"
     ]
    }
   ],
   "source": [
    "endpoint_config_name = 'DEMO-MultiModelGluonTSEndpointConfig-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print('Endpoint config name: ' + endpoint_config_name)\n",
    "\n",
    "create_endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName = endpoint_config_name,\n",
    "    ProductionVariants=[{\n",
    "        'InstanceType': 'ml.m5.xlarge',\n",
    "        'InitialInstanceCount': 2,\n",
    "        'InitialVariantWeight': 1,\n",
    "        'ModelName': model_name,\n",
    "        'VariantName': 'AllTraffic'}])\n",
    "\n",
    "print(\"Endpoint config Arn: \" + create_endpoint_config_response['EndpointConfigArn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the multi model endpoint\n",
    "\n",
    "엔드포인트 생성 또한 단일 모델 엔드포인트와 동일한 방식입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint name: DEMO-MultiModelGluonTSEndpoint-2021-04-08-14-47-12\n",
      "Endpoint Arn: arn:aws:sagemaker:us-east-1:143656149352:endpoint/demo-multimodelgluontsendpoint-2021-04-08-14-47-12\n",
      "Endpoint Status: Creating\n",
      "Waiting for DEMO-MultiModelGluonTSEndpoint-2021-04-08-14-47-12 endpoint to be in service...\n"
     ]
    }
   ],
   "source": [
    "endpoint_name = 'DEMO-MultiModelGluonTSEndpoint-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print('Endpoint name: ' + endpoint_name)\n",
    "\n",
    "create_endpoint_response = sm_client.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=endpoint_config_name)\n",
    "print('Endpoint Arn: ' + create_endpoint_response['EndpointArn'])\n",
    "\n",
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp['EndpointStatus']\n",
    "print(\"Endpoint Status: \" + status)\n",
    "\n",
    "print('Waiting for {} endpoint to be in service...'.format(endpoint_name))\n",
    "waiter = sm_client.get_waiter('endpoint_in_service')\n",
    "waiter.wait(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Invoke models\n",
    "\n",
    "호스팅 엔드포인트가 생성되었으면, 이전 과정에서 S3에 업로드한 모델을 호출합니다. 최초 호출 시에 SageMaker가 S3에서 인스턴스로 모델 아티팩트를 다운로드하고 컨테이너에 로드하기 때문에 호출 속도가 느릴 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Invoke the Mean Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 모델을 호출하기 위한 페이로드로 두 개의 시계열을 준비한 다음 boto3 API의 `InvokeEndpoint`를 호출합니다. `TargetModel` 필드는 모델을 생성 할 때 `ModelDataUrl`에 지정된 S3 prefix와 연결되어 S3에서 모델의 위치를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "    data = []\n",
    "    with jsonlines.open(file_path) as reader:\n",
    "        for obj in reader:\n",
    "            data.append(obj)\n",
    "    return data\n",
    "\n",
    "payload_jsonline = read_data('data/test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_time_series = 2 # select 2 time series for quick response\n",
    "payload_list = []\n",
    "for p in payload_jsonline[:n_time_series]:\n",
    "    payload_list.append(json.dumps(p))\n",
    "payload = '\\n'.join(payload_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inference_result(runtime_sm_client, endpoint_name, model_filename, request_body):\n",
    "\n",
    "    response = runtime_sm_client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        ContentType='application/json',\n",
    "        TargetModel=model_filename, # this is the rest of the S3 path where the model artifacts are located\n",
    "        Body=payload)\n",
    "    result = response['Body'].read().decode('utf-8')\n",
    "    \n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"item_id\": \"0\", \"quantiles\": {\"0.1\": [1.810399608829874, 1.8131818477080341, 1.4484505582328373, 1.5365462275284603, 1.6998268218274881, 1.6555417070853777, 1.5886599334362295, 1.639505339658033, 1.6866150796250512, 1.5103819152027935, 1.6573544609794224, 1.477236348409322], \"0.2\": [2.0260910161621637, 1.913265705112409, 2.021964203687525, 2.0387477820909647, 1.864360129659764, 1.9669942837326502, 1.8864997919735464, 1.9759512325561546, 2.0050252881844894, 1.8281849066256193, 1.9122738252257485, 1.763851960399548], \"0.3\": [2.2130347358771334, 2.1675520943536593, 2.1846103985492267, 2.1434094349881727, 2.1221213832251533, 2.185128123979893, 2.091302927070566, 2.2356458614508394, 2.1526344102236483, 2.057776659342696, 2.113431188791634, 2.101374557166642], \"0.4\": [2.458741711111396, 2.3912627576654364, 2.291338040845962, 2.341335484458328, 2.315010654809142, 2.379071081558289, 2.328475072132477, 2.425226805988193, 2.419037162644797, 2.271509438164376, 2.4003791674309682, 2.305079916704785], \"0.5\": [2.642527061055181, 2.5387921744276647, 2.6352199023673784, 2.5522023221359222, 2.596172528301504, 2.505358741935539, 2.454701150310571, 2.587384245046242, 2.7060499908689155, 2.556122796292618, 2.6036427059716294, 2.6134649119533484], \"0.6\": [2.899067134564383, 2.710149001578841, 2.747292763742332, 2.6823859737450504, 2.802476856791768, 2.6239364339218545, 2.6307152032479646, 2.7265698497258684, 2.7822648811023236, 2.741526337985436, 2.7009011323598355, 2.782170876315634], \"0.7\": [3.020616447227556, 3.01454719828084, 2.998504437429377, 3.006317321688973, 3.058203782697379, 2.7794847743468836, 3.017972761783208, 3.1339846789966552, 2.910458070628716, 2.880479437978176, 2.9064767147691035, 2.996509699495871], \"0.8\": [3.2728787424454664, 3.239042031588986, 3.380737879645415, 3.2322965525873704, 3.3052794474663973, 3.0771824715201177, 3.2772948705724243, 3.437807816738092, 3.0336136989314135, 3.064862402341811, 3.304811729363384, 3.3716731583221673], \"0.9\": [3.664230838764965, 3.610958717526315, 3.6214834232627355, 3.694670236769482, 3.6902234072614926, 3.679921555160579, 3.4924793314660647, 3.709028719695618, 3.444337499493737, 3.243734119696114, 3.7121579366945348, 3.7211258070120206]}, \"mean\": [2.6634026902562855, 2.620237422561233, 2.5969109818835734, 2.581655643798769, 2.605573866623061, 2.5510443520822483, 2.550287597938557, 2.6076236617507904, 2.576236693453398, 2.4489370773323746, 2.605062015046758, 2.562488490624205]}\n",
      "{\"item_id\": \"1\", \"quantiles\": {\"0.1\": [23.859288646024435, 23.83513570155716, 24.430415313845696, 24.86922150330002, 23.80620715783646, 23.899137542978544, 23.876514227499122, 24.228185217611763, 23.209144949069817, 23.521519886750255, 25.23715758585801, 23.578840630582302], \"0.2\": [25.636666661932033, 25.530312909355835, 25.91084640771291, 26.06900830475617, 25.49689989826555, 24.891933110394685, 25.49555960129415, 26.479694764818326, 25.632400908150238, 25.91697611651609, 26.466687021851882, 25.5451396262875], \"0.3\": [26.74073613778134, 26.29868330165759, 27.23641238505107, 27.157898463282027, 26.452067616303037, 26.040800524507166, 26.20840035517286, 27.602878602191204, 26.468456625770315, 27.12410898093299, 27.676366256484872, 26.692907304989113], \"0.4\": [27.592383966430987, 27.40088965310249, 28.188866230942548, 28.29305707748404, 27.60242301740835, 27.168186436565883, 27.959013347046614, 28.440664455908266, 28.387474038470362, 28.200431212888848, 28.164818423892445, 28.212678944992653], \"0.5\": [28.853035982552033, 28.2796252338991, 28.623568309173596, 29.014219994905737, 28.39785714312717, 28.729147504109974, 29.20784834854052, 29.755986254579273, 29.291221405888383, 29.483834468952946, 29.302168345887665, 29.03112998889255], \"0.6\": [29.578965746115642, 29.3731416602599, 29.572393710044388, 29.659117264130334, 29.154156271520527, 29.240570172506782, 30.12295148111282, 30.537613388365756, 29.809752062877966, 30.071191522664808, 30.226205626694405, 30.2005885816459], \"0.7\": [31.20254368332889, 30.177853337928628, 31.107652984025183, 30.560580369596757, 30.324816031569988, 31.0412771936848, 31.327901855941786, 31.501954874408653, 30.875250765376656, 31.096358887397308, 30.962811201668597, 31.164532024865753], \"0.8\": [32.66458465438033, 31.999783929161918, 31.96326785325759, 31.67808597486166, 31.991475138178174, 31.82716847580696, 32.33916108444118, 32.564481971462605, 32.54242893067891, 32.01575679104063, 32.2409159617324, 31.644734701745215], \"0.9\": [33.68395037124657, 33.397962290330554, 34.45548600238399, 33.79890275637237, 33.521035834219745, 32.810507654484894, 33.746139146892276, 33.88258868647281, 34.086832552833535, 33.18475796023131, 34.63801377933423, 34.23691866043379]}, \"mean\": [28.886220939723074, 28.456824385269115, 29.153851030807637, 28.95531309477603, 28.486843912392498, 28.395506578601303, 28.82258391709567, 29.4047366692801, 28.732993077426855, 28.859658191959905, 29.45814716220808, 28.909251328244103]}\n",
      "\n",
      "CPU times: user 13 ms, sys: 50 µs, total: 13 ms\n",
      "Wall time: 4.64 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result_mean = get_inference_result(runtime_sm_client, endpoint_name, 'MeanPredictor.tar.gz', payload)\n",
    "print(result_mean, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최초 호출 이후, 두 번째로 동일한 모델을 호출하면 이미 인스턴스에 다운로드되고 컨테이너에 로드되므로 추론이 빠르게 수행됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"item_id\": \"0\", \"quantiles\": {\"0.1\": [1.4654508260529162, 1.423891781689255, 1.7757414822262154, 1.5864920155198812, 1.5900224350424936, 1.6646010649063432, 1.5181594989210836, 1.8364850132854333, 1.4626581356351, 1.470558835612606, 1.475199890108488, 1.4323098654172937], \"0.2\": [1.7768910447676578, 1.839694094921167, 2.146634543612159, 1.903434177590697, 1.9059980577206503, 1.8943988644221235, 1.9303880187593374, 2.1528906218255472, 1.9011312788981112, 1.9319513250012816, 1.8426904338757735, 1.8479433735445698], \"0.3\": [1.9592398504988617, 2.1374060116459663, 2.4041354155496837, 2.092304273981136, 2.090190529897593, 2.2635209121125155, 2.1114415033457847, 2.452898443884457, 2.300691587370901, 2.0984121160878244, 2.2409590866158497, 2.076098552490381], \"0.4\": [2.217468917503038, 2.3136295758431977, 2.557049906375984, 2.2318131010962796, 2.344065100871651, 2.4444397200257795, 2.3628398849195316, 2.542455693954407, 2.4748433616432886, 2.3036864768588834, 2.3729759310392065, 2.4240059723470995], \"0.5\": [2.427902879250797, 2.5317262835354892, 2.8202174820789194, 2.3636550817437523, 2.452274700367193, 2.6474068224665177, 2.567428200498842, 2.6629604268598523, 2.7701330986918116, 2.4978265960620747, 2.5830360429044017, 2.577416304355059], \"0.6\": [2.6872368290850797, 2.6848361399943763, 2.9564270878747934, 2.718434025203498, 2.7526834503145197, 2.7829127458979794, 2.7222879184009936, 2.818591569536143, 2.893168782717121, 2.7393251125400706, 2.7790084676512476, 2.8087603724882286], \"0.7\": [2.890662257795593, 2.845497015274214, 3.139681663883163, 2.9226626105026154, 2.836827595030864, 2.974143616378496, 3.0045444297892367, 3.044113816148636, 3.183245776331937, 2.9089192608428935, 2.9463461455523254, 2.982830583279161], \"0.8\": [3.1419406968822594, 3.0940753872435662, 3.4045004806661456, 3.235750936121873, 3.0553091153435528, 3.1335417132889676, 3.2039814336762404, 3.268177658484986, 3.4487661624226758, 3.2214933685155662, 3.228601475846413, 3.310755999884515], \"0.9\": [3.605301214052714, 3.31157266403532, 3.588223949216611, 3.4403304901681713, 3.3444087330069907, 3.570700391512907, 3.4356234524848657, 3.6031385768574005, 3.7591533574529947, 3.480163877456012, 3.405309112365053, 3.5420062955793092]}, \"mean\": [2.4690218352384092, 2.4502778529305953, 2.6959873132178926, 2.4922537675604035, 2.491344332916033, 2.6172951574036034, 2.524541997684902, 2.7129464435908375, 2.6680170406858212, 2.5202823152111513, 2.5582530279955153, 2.567910700092257]}\n",
      "{\"item_id\": \"1\", \"quantiles\": {\"0.1\": [23.831396112874792, 24.09706056766954, 24.86165747898731, 23.99688651634813, 23.906396773833926, 23.798443181083368, 24.65887398899273, 24.527678470449867, 24.905254376051086, 24.604039753454504, 24.618749081840996, 24.72982172981718], \"0.2\": [25.07152825487993, 25.494279969092606, 26.04518055308346, 25.72691881400657, 25.58873927538222, 25.06473372564328, 26.15997145900645, 25.507137055433752, 26.310994812983992, 25.83604005600059, 25.81817134743802, 26.08952065658539], \"0.3\": [26.501877646227342, 26.27654288245472, 27.040112672883872, 27.364030045433964, 27.45705503137228, 26.866450671928938, 27.12501588800268, 26.953478913442904, 27.214016476894255, 26.56453774246376, 26.657713278370068, 27.268532165145114], \"0.4\": [27.785978096508583, 27.709925939851075, 28.259812389344614, 28.1374259931508, 27.70776022408277, 27.997209242078196, 28.036274546618092, 27.976957106980734, 27.876772716045757, 27.64217860452436, 27.383699489000218, 28.136162678867166], \"0.5\": [28.705195058832516, 28.97053597823829, 28.87514844037189, 29.621792258976594, 28.4387381216938, 28.70566443630837, 28.75067258760152, 28.75818452755979, 28.58451229210797, 28.635934686030524, 28.30661005273065, 29.1825603744795], \"0.6\": [29.221770429753008, 30.226672727533497, 29.423899582577928, 30.434219562986343, 29.078976517601916, 30.17869236476547, 29.768828371057424, 29.05957304850584, 29.565925960065652, 29.12975110455379, 29.47719341147647, 29.938638044126098], \"0.7\": [30.462532236866725, 30.803847251225392, 30.174668121988848, 31.628426364782097, 30.044781978507412, 31.042895487902694, 30.761313128719188, 29.9356146717137, 30.560075983393475, 29.813198049434128, 30.43503299830587, 31.712353376642], \"0.8\": [32.062191728219894, 32.420821239326266, 31.51856463170064, 32.885942686668166, 31.004722075947157, 32.35321534776288, 32.57063188208943, 30.859460004658292, 31.506644508804307, 30.704898456746054, 31.766710771168647, 32.89207476808457], \"0.9\": [33.64202230930442, 34.210160115121305, 32.84239967619606, 34.079813695924436, 32.25068653181228, 34.409133006865986, 34.011546439864915, 32.380230557316565, 33.01569880929065, 32.23961692241389, 33.38268695739167, 34.27388507297957]}, \"mean\": [28.64826192714903, 28.98148045018942, 28.727773459866597, 29.406054840220193, 28.307939247671065, 28.928244866079122, 29.06248142602802, 28.35146132805539, 28.86031307339286, 28.460654593871528, 28.67408107548687, 29.340601040235068]}\n",
      "\n",
      "CPU times: user 3.78 ms, sys: 0 ns, total: 3.78 ms\n",
      "Wall time: 22.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result_mean = get_inference_result(runtime_sm_client, endpoint_name, 'MeanPredictor.tar.gz', payload)\n",
    "print(result_mean, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Invoke multi models\n",
    "\n",
    "멀티모델 엔드포인트의 힘을 발휘하여 다른 모델 (예: `DeepAREstimator.tar.gz`)을 `TargetModel`로 지정하고 동일한 엔드포인트를 사용하여 추론을 수행할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_naive = get_inference_result(runtime_sm_client, endpoint_name, 'SeasonalNaivePredictor.tar.gz', payload)\n",
    "result_prophet = get_inference_result(runtime_sm_client, endpoint_name, 'ProphetPredictor.tar.gz', payload)\n",
    "result_ffn = get_inference_result(runtime_sm_client, endpoint_name, 'SimpleFeedForwardEstimator.tar.gz', payload)\n",
    "result_deepar = get_inference_result(runtime_sm_client, endpoint_name, 'DeepAREstimator.tar.gz', payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"item_id\": \"0\", \"quantiles\": {\"0.1\": [2.5666637420654297, 2.8132734298706055, 2.6296422481536865, 2.8897743225097656, 3.470712423324585, 3.577692985534668, 3.3943748474121094, 2.4244911670684814, 2.2983062267303467, 2.5657153129577637, 2.6624789237976074, 2.5903286933898926], \"0.2\": [2.7564260959625244, 2.984457015991211, 2.9986135959625244, 3.050806760787964, 3.607384204864502, 3.687776803970337, 3.5164635181427, 2.585606813430786, 2.5066545009613037, 2.725512742996216, 2.7753734588623047, 2.732186794281006], \"0.3\": [2.8530142307281494, 3.0957539081573486, 3.0873405933380127, 3.184116840362549, 3.8131134510040283, 3.825244426727295, 3.601621150970459, 2.6971001625061035, 2.586515188217163, 2.8266780376434326, 2.87007474899292, 2.8411788940429688], \"0.4\": [2.9325153827667236, 3.1580684185028076, 3.1143741607666016, 3.3106939792633057, 3.866978883743286, 3.9082369804382324, 3.7005550861358643, 2.7283027172088623, 2.670076847076416, 2.948002576828003, 2.925839900970459, 2.88446307182312], \"0.5\": [3.022904396057129, 3.2254886627197266, 3.227041721343994, 3.3928775787353516, 3.951112985610962, 3.9744746685028076, 3.7547152042388916, 2.814244508743286, 2.7632696628570557, 3.055704355239868, 2.9974117279052734, 2.94352126121521], \"0.6\": [3.1072375774383545, 3.313610076904297, 3.279329299926758, 3.4352591037750244, 4.030699729919434, 4.007991313934326, 3.8239994049072266, 2.8448708057403564, 2.8362624645233154, 3.1038739681243896, 3.1118640899658203, 3.0493412017822266], \"0.7\": [3.171215295791626, 3.4461312294006348, 3.325253963470459, 3.526487112045288, 4.088061332702637, 4.057263374328613, 3.896388053894043, 2.8765006065368652, 2.936170816421509, 3.1898837089538574, 3.199204921722412, 3.131635904312134], \"0.8\": [3.287252902984619, 3.5245206356048584, 3.433262348175049, 3.6746644973754883, 4.172996520996094, 4.184357643127441, 3.9349148273468018, 2.9908885955810547, 3.0743088722229004, 3.264129638671875, 3.282104730606079, 3.2254762649536133], \"0.9\": [3.4721755981445312, 3.668626546859741, 3.549909830093384, 3.8268134593963623, 4.397966384887695, 4.391365051269531, 4.052274703979492, 3.127049207687378, 3.2921979427337646, 3.3588945865631104, 3.4164583683013916, 3.3582067489624023]}, \"mean\": [3.0051047801971436, 3.2739996910095215, 3.1859264373779297, 3.3374240398406982, 3.9009008407592773, 3.9453177452087402, 3.740913152694702, 2.7846643924713135, 2.7918853759765625, 3.0072689056396484, 3.010744571685791, 2.9840524196624756]}\n",
      "{\"item_id\": \"1\", \"quantiles\": {\"0.1\": [25.420181274414062, 28.39781951904297, 32.831092834472656, 36.91093826293945, 38.028629302978516, 37.912479400634766, 37.72367477416992, 36.612369537353516, 39.214271545410156, 38.42606735229492, 32.552974700927734, 29.374055862426758], \"0.2\": [26.406496047973633, 29.056564331054688, 33.75701141357422, 37.74126434326172, 39.16769790649414, 39.10063171386719, 38.61317825317383, 38.26527404785156, 40.06502914428711, 39.033164978027344, 34.563682556152344, 31.0924072265625], \"0.3\": [26.65101432800293, 29.7369384765625, 34.43152618408203, 38.59522247314453, 40.107540130615234, 39.80134582519531, 39.30584716796875, 38.89948654174805, 40.90483856201172, 39.91242980957031, 35.3259391784668, 31.549501419067383], \"0.4\": [27.52323341369629, 30.51034164428711, 34.999568939208984, 39.24909210205078, 40.674644470214844, 40.818870544433594, 39.73614501953125, 39.36128234863281, 41.49677276611328, 40.494384765625, 35.76417922973633, 32.15702438354492], \"0.5\": [28.09764289855957, 31.034080505371094, 35.521522521972656, 39.89891815185547, 41.534034729003906, 41.43463897705078, 40.32954406738281, 39.80254364013672, 42.12301254272461, 41.31652069091797, 36.29768371582031, 32.77785110473633], \"0.6\": [28.411909103393555, 31.56351661682129, 35.84734344482422, 40.308616638183594, 42.45789337158203, 41.92970657348633, 40.89268493652344, 40.409690856933594, 42.603145599365234, 41.63926315307617, 37.021690368652344, 33.15425491333008], \"0.7\": [28.89752960205078, 32.3328742980957, 36.66083908081055, 40.961055755615234, 43.23698043823242, 42.14772415161133, 41.42943572998047, 41.01816940307617, 43.64046096801758, 42.4549446105957, 37.33192443847656, 33.723182678222656], \"0.8\": [29.8016414642334, 33.3358039855957, 37.8205680847168, 42.60848617553711, 43.6584358215332, 43.00434875488281, 42.631771087646484, 42.06306457519531, 45.123252868652344, 43.072696685791016, 38.29381561279297, 34.461917877197266], \"0.9\": [31.195173263549805, 34.732093811035156, 40.27649688720703, 43.78660583496094, 44.36458969116211, 44.68574142456055, 43.90634536743164, 44.3927001953125, 46.59046936035156, 44.4135627746582, 38.91050338745117, 35.47623825073242]}, \"mean\": [28.174360275268555, 31.0579891204834, 36.325504302978516, 40.04898452758789, 41.387088775634766, 41.23576354980469, 40.79030990600586, 40.10408020019531, 42.61637878417969, 41.34025573730469, 35.49615478515625, 32.70682907104492]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(result_deepar, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 3. Batch Transform in the Multi-Model Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MMS는 배치 변환(batch transform)을 직접 지원하지 않기 때문에, SageMaker에서 별도로 모델을 생성하고 각 모델에 대해 하나씩 배치 변환을 수행해야 합니다. 아래는 하나의 모델에 대해 배치 변환을 수행하는 예시를 보여줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Create the Sagemaker model from the model artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: DEMO-GluonTSModel-DeepAREstimator-2021-04-08-14-56-02\n",
      "Model data Url: https://s3-us-east-1.amazonaws.com/sagemaker-us-east-1-143656149352/demo-multimodel-gluonts-endpoint/models/DeepAREstimator.tar.gz\n",
      "Container image: 143656149352.dkr.ecr.us-east-1.amazonaws.com/demo-sagemaker-multimodel-gluonts:latest\n",
      "Model Arn: arn:aws:sagemaker:us-east-1:143656149352:model/demo-gluontsmodel-deeparestimator-2021-04-08-14-56-02\n"
     ]
    }
   ],
   "source": [
    "from time import gmtime, strftime\n",
    "\n",
    "model = 'DeepAREstimator'\n",
    "model_name_bt = 'DEMO-GluonTSModel-{}-'.format(model) + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "model_url = 'https://s3-{}.amazonaws.com/{}/{}/{}/{}.tar.gz'.format(region, bucket, prefix, models_dir, model)\n",
    "container = '{}.dkr.ecr.{}.amazonaws.com/{}:latest'.format(account_id, region, 'demo-sagemaker-multimodel-gluonts')\n",
    "\n",
    "print('Model name: ' + model_name_bt)\n",
    "print('Model data Url: ' + model_url)\n",
    "print('Container image: ' + container)\n",
    "\n",
    "container = {\n",
    "    'Image': container,\n",
    "    'ModelDataUrl': model_url,\n",
    "    'Mode': 'SingleModel'\n",
    "}\n",
    "\n",
    "create_model_response = sm_client.create_model(\n",
    "    ModelName = model_name_bt,\n",
    "    ExecutionRoleArn = role,\n",
    "    Containers = [container])\n",
    "\n",
    "print(\"Model Arn: \" + create_model_response['ModelArn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Start the Batch Transform Job Using the Model Created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TransformJobArn': 'arn:aws:sagemaker:us-east-1:143656149352:transform-job/demo-gluonts-deeparestimator-bt-2021-04-08-14-56-02',\n",
       " 'ResponseMetadata': {'RequestId': 'b8aae7a2-1cb4-495c-b4a7-ed16ef62acf2',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'b8aae7a2-1cb4-495c-b4a7-ed16ef62acf2',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '128',\n",
       "   'date': 'Thu, 08 Apr 2021 14:56:02 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_s3_path = \"s3://{}/{}/data/test.json\".format(bucket, prefix)\n",
    "transform_job_name = 'DEMO-GluonTS-{}-BT-'.format(model) + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "transform_input = {\n",
    "        'DataSource': {\n",
    "            'S3DataSource': {\n",
    "                'S3DataType': 'S3Prefix',\n",
    "                'S3Uri': test_data_s3_path\n",
    "            }\n",
    "        },\n",
    "        'ContentType': 'application/json',\n",
    "        'CompressionType': 'None',\n",
    "        'SplitType': 'Line'\n",
    "    }\n",
    "\n",
    "transform_output = {\n",
    "        'S3OutputPath': 's3://{}/{}/inference-results/{}'.format(bucket,prefix, model),\n",
    "    }\n",
    "\n",
    "transform_resources = {\n",
    "        'InstanceType': 'ml.m5.xlarge',\n",
    "        'InstanceCount': 1\n",
    "    }\n",
    "\n",
    "sm_client.create_transform_job(TransformJobName = transform_job_name,\n",
    "                        ModelName = model_name_bt,\n",
    "                        BatchStrategy='SingleRecord',\n",
    "                        TransformInput = transform_input,\n",
    "                        TransformOutput = transform_output,\n",
    "                        TransformResources = transform_resources\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Check the Batch Transform Job Status\n",
    "\n",
    "모든 데이터에 대해 추론을 수행하므로, 약간의 시간이 소요됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JobStatus\n",
      "----------\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "print ('JobStatus')\n",
    "print('----------')\n",
    "from time import sleep\n",
    "\n",
    "describe_response = sm_client.describe_transform_job(TransformJobName = transform_job_name)\n",
    "job_run_status = describe_response['TransformJobStatus']\n",
    "print (job_run_status)\n",
    "\n",
    "while job_run_status not in ('Failed', 'Completed', 'Stopped'):\n",
    "    describe_response = sm_client.describe_transform_job(TransformJobName = transform_job_name)\n",
    "    job_run_status = describe_response['TransformJobStatus']\n",
    "    print (job_run_status)\n",
    "    sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Inspect Batch Transform Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'item_id': '0', 'quantiles': {'0.1': [2.5666637420654297, 2.8132734298706055, 2.6296422481536865, 2.8897743225097656, 3.470712423324585, 3.577692985534668, 3.3943748474121094, 2.4244911670684814, 2.2983062267303467, 2.5657153129577637, 2.6624789237976074, 2.5903286933898926], '0.2': [2.7564260959625244, 2.984457015991211, 2.9986135959625244, 3.050806760787964, 3.607384204864502, 3.687776803970337, 3.5164635181427, 2.585606813430786, 2.5066545009613037, 2.725512742996216, 2.7753734588623047, 2.732186794281006], '0.3': [2.8530142307281494, 3.0957539081573486, 3.0873405933380127, 3.184116840362549, 3.8131134510040283, 3.825244426727295, 3.601621150970459, 2.6971001625061035, 2.586515188217163, 2.8266780376434326, 2.87007474899292, 2.8411788940429688], '0.4': [2.9325153827667236, 3.1580684185028076, 3.1143741607666016, 3.3106939792633057, 3.866978883743286, 3.9082369804382324, 3.7005550861358643, 2.7283027172088623, 2.670076847076416, 2.948002576828003, 2.925839900970459, 2.88446307182312], '0.5': [3.022904396057129, 3.2254886627197266, 3.227041721343994, 3.3928775787353516, 3.951112985610962, 3.9744746685028076, 3.7547152042388916, 2.814244508743286, 2.7632696628570557, 3.055704355239868, 2.9974117279052734, 2.94352126121521], '0.6': [3.1072375774383545, 3.313610076904297, 3.279329299926758, 3.4352591037750244, 4.030699729919434, 4.007991313934326, 3.8239994049072266, 2.8448708057403564, 2.8362624645233154, 3.1038739681243896, 3.1118640899658203, 3.0493412017822266], '0.7': [3.171215295791626, 3.4461312294006348, 3.325253963470459, 3.526487112045288, 4.088061332702637, 4.057263374328613, 3.896388053894043, 2.8765006065368652, 2.936170816421509, 3.1898837089538574, 3.199204921722412, 3.131635904312134], '0.8': [3.287252902984619, 3.5245206356048584, 3.433262348175049, 3.6746644973754883, 4.172996520996094, 4.184357643127441, 3.9349148273468018, 2.9908885955810547, 3.0743088722229004, 3.264129638671875, 3.282104730606079, 3.2254762649536133], '0.9': [3.4721755981445312, 3.668626546859741, 3.549909830093384, 3.8268134593963623, 4.397966384887695, 4.391365051269531, 4.052274703979492, 3.127049207687378, 3.2921979427337646, 3.3588945865631104, 3.4164583683013916, 3.3582067489624023]}, 'mean': [3.0051047801971436, 3.2739996910095215, 3.1859264373779297, 3.3374240398406982, 3.9009008407592773, 3.9453177452087402, 3.740913152694702, 2.7846643924713135, 2.7918853759765625, 3.0072689056396484, 3.010744571685791, 2.9840524196624756]}, {'item_id': '1', 'quantiles': {'0.1': [24.894113540649414, 27.2794132232666, 31.723888397216797, 36.19679260253906, 37.22895431518555, 38.14207458496094, 37.579315185546875, 37.06891632080078, 38.27815628051758, 37.94804000854492, 33.04309844970703, 29.6630802154541], '0.2': [26.296987533569336, 28.535425186157227, 33.72280502319336, 37.57625961303711, 38.82698059082031, 39.47317123413086, 38.792232513427734, 37.783443450927734, 39.83594512939453, 39.025291442871094, 34.524017333984375, 30.971576690673828], '0.3': [27.027172088623047, 29.610624313354492, 34.34794235229492, 38.65596008300781, 39.898414611816406, 40.141109466552734, 39.47340393066406, 38.55045700073242, 40.523704528808594, 40.14765167236328, 35.13987731933594, 31.886281967163086], '0.4': [27.61587142944336, 30.215038299560547, 34.72886276245117, 39.34999084472656, 40.71078109741211, 40.83061981201172, 39.80555725097656, 39.348472595214844, 41.14567184448242, 40.67982482910156, 35.61869430541992, 32.241722106933594], '0.5': [28.298978805541992, 30.82459831237793, 35.4821662902832, 39.99934387207031, 41.295936584472656, 41.333526611328125, 40.45502853393555, 40.02212905883789, 41.606597900390625, 41.6387939453125, 36.48629379272461, 32.609222412109375], '0.6': [28.92970085144043, 31.374345779418945, 35.730281829833984, 40.78464889526367, 41.78693771362305, 41.68400955200195, 40.8619499206543, 40.34372329711914, 42.08085250854492, 41.949275970458984, 37.110382080078125, 33.23685836791992], '0.7': [29.399120330810547, 32.097320556640625, 36.31716537475586, 41.304290771484375, 42.63371276855469, 42.19172668457031, 41.348602294921875, 41.05438232421875, 42.670658111572266, 42.46796798706055, 37.840354919433594, 34.00054168701172], '0.8': [30.28497314453125, 32.791133880615234, 37.266605377197266, 42.34774398803711, 43.44425582885742, 43.128055572509766, 41.82423400878906, 41.67710494995117, 44.03417205810547, 43.3466796875, 38.0991096496582, 34.55641174316406], '0.9': [31.59315299987793, 33.562679290771484, 39.452796936035156, 43.48133850097656, 44.41031265258789, 45.028724670410156, 42.87324142456055, 42.76728057861328, 45.59819030761719, 44.280364990234375, 39.03622055053711, 35.26302719116211]}, 'mean': [28.164962768554688, 30.685842514038086, 35.818294525146484, 39.978607177734375, 40.94489669799805, 41.4884033203125, 40.498748779296875, 39.789005279541016, 41.788299560546875, 41.35905456542969, 36.20930480957031, 32.722476959228516]}]\n"
     ]
    }
   ],
   "source": [
    "s3_client = boto3.client('s3')\n",
    "s3_client.download_file(Filename='data/test.json.out',\n",
    "                        Bucket=bucket,\n",
    "                        Key='{}/inference-results/{}/test.json.out'.format(prefix, model))\n",
    "test_out_jsonline = read_data('data/test.json.out')\n",
    "print(test_out_jsonline[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. (Optional) Clean-up the resources\n",
    "\n",
    "불필요한 과금을 막기 위해 핸즈온을 모두 완료하였으면, 엔드포인트를 삭제합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '2180b4c2-5a2f-48b7-a44b-fc69e69c2e8b',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '2180b4c2-5a2f-48b7-a44b-fc69e69c2e8b',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '0',\n",
       "   'date': 'Thu, 08 Apr 2021 15:05:00 GMT'},\n",
       "  'RetryAttempts': 2}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "sm_client.delete_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
    "sm_client.delete_model(ModelName=model_name)\n",
    "sm_client.delete_model(ModelName=model_name_bt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
